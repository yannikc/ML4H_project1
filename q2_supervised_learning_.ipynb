{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:34:17.725534Z",
     "start_time": "2025-03-30T08:34:13.546725Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import glob"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Classic Machine Learning Methods (5 Pts)\n",
    "#### Q2.1 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:34:20.505469Z",
     "start_time": "2025-03-30T08:34:20.356043Z"
    }
   },
   "source": [
    "# Retrieving the X matrix\n",
    "df = pd.read_parquet('final-data/final-set-a.parquet')\n",
    "df = df.fillna(0)\n",
    "X = df.groupby(\"RecordID\").last(numeric_only=True).reset_index()\n",
    "X = X.drop(columns=[\"RecordID\"])\n",
    "X = X[sorted(X.columns)]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:34:21.713479Z",
     "start_time": "2025-03-30T08:34:21.706037Z"
    }
   },
   "source": [
    "# Retrieving the label vector\n",
    "y_df = pd.read_parquet('processed-data/processed-outcomes-a.parquet')\n",
    "y = y_df[\"In-hospital_death\"].to_numpy().flatten()\n",
    "print(y.sum())\n",
    "print(len(y))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554\n",
      "4000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:34:29.032583Z",
     "start_time": "2025-03-30T08:34:23.287398Z"
    }
   },
   "source": [
    "# Logistic Regression\n",
    "model1 = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "model1.fit(X,y)\n",
    "\n",
    "# Random Forest\n",
    "model2 = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    min_samples_split=5,    \n",
    "    min_samples_leaf=2,         \n",
    "    class_weight='balanced',\n",
    "    random_state=42,        \n",
    ")\n",
    "model2.fit(X,y)\n",
    "\n",
    "# KNN\n",
    "model3 = KNeighborsClassifier(\n",
    "    n_neighbors=150,\n",
    "    weights='distance',\n",
    "    metric='manhattan',\n",
    ")\n",
    "model3.fit(X,y)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=150, weights='distance')"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=150, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=150, weights=&#x27;distance&#x27;)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:34:40.654635Z",
     "start_time": "2025-03-30T08:34:39.019668Z"
    }
   },
   "source": [
    "# Test set C performance\n",
    "\n",
    "# Loading test set C\n",
    "df = pd.read_parquet('final-data/final-set-c.parquet')\n",
    "df = df.fillna(0)\n",
    "df = df.drop(columns=[\"ICUType\"])\n",
    "X_test = df.groupby(\"RecordID\").last(numeric_only=True).reset_index()\n",
    "X_test = X_test.drop(columns=[\"RecordID\"])\n",
    "X_test= X_test[sorted(X_test.columns)]\n",
    "\n",
    "y_df = pd.read_parquet('processed-data/processed-outcomes-c.parquet')\n",
    "y_test = y_df[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "y_pred1 = model1.predict_proba(X_test)[:,1]\n",
    "y_pred2 = model2.predict_proba(X_test)[:,1]\n",
    "y_pred3 = model3.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculation of AuROC and AuPRC for Logistic Regression\n",
    "print(\"Logistic Regression results\")\n",
    "auroc = roc_auc_score(y_test, y_pred1)\n",
    "print(f\"AUROC: {auroc}\")\n",
    "auprc = average_precision_score(y_test, y_pred1)\n",
    "print(f\"AUPRC: {auprc}\", end=\"\\n\\n\")\n",
    "\n",
    "# Calculation of AuROC and AuPRC for Random Forests\n",
    "print(\"Random Forests results\")\n",
    "auroc = roc_auc_score(y_test, y_pred2)\n",
    "print(f\"AUROC: {auroc}\")\n",
    "auprc = average_precision_score(y_test, y_pred2)\n",
    "print(f\"AUPRC: {auprc}\", end=\"\\n\\n\")\n",
    "\n",
    "# Calculation of AuROC and AuPRC for KNN\n",
    "print(\"KNN results\")\n",
    "auroc = roc_auc_score(y_test, y_pred3)\n",
    "print(f\"AUROC: {auroc}\")\n",
    "auprc = average_precision_score(y_test, y_pred3)\n",
    "print(f\"AUPRC: {auprc}\", end=\"\\n\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression results\n",
      "AUROC: 0.8446701955925967\n",
      "AUPRC: 0.4985580595691314\n",
      "\n",
      "Random Forests results\n",
      "AUROC: 0.8554166510242646\n",
      "AUPRC: 0.5120231760871147\n",
      "\n",
      "KNN results\n",
      "AUROC: 0.8367941835291762\n",
      "AUPRC: 0.4887275415574222\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1 2."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:35:28.969221Z",
     "start_time": "2025-03-30T08:34:45.594091Z"
    }
   },
   "source": [
    "extraction_settings = MinimalFCParameters()\n",
    "\n",
    "# Extracting features of concatenated training and test dataset (need to do this in one go so the feature extraction is consistent)\n",
    "df_train = pd.read_parquet('final-data/final-set-a.parquet')\n",
    "df_test = pd.read_parquet('final-data/final-set-c.parquet').drop(columns=[\"ICUType\"])\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "X_train = extract_features(df_train, column_id='RecordID', column_sort='Time', default_fc_parameters=extraction_settings, impute_function=impute)\n",
    "X_test = extract_features(df_test, column_id='RecordID', column_sort='Time', default_fc_parameters=extraction_settings, impute_function=impute)\n",
    "\n",
    "X_train= X_train[sorted(X_train.columns)]\n",
    "X_test= X_test[sorted(X_test.columns)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196000, 42)\n",
      "(196000, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:20<00:00,  1.03s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:35:48.915381Z",
     "start_time": "2025-03-30T08:35:48.905208Z"
    }
   },
   "source": [
    "y_train = pd.read_parquet('processed-data/processed-outcomes-a.parquet')[\"In-hospital_death\"].to_numpy().flatten()\n",
    "y_test = pd.read_parquet('processed-data/processed-outcomes-c.parquet')[\"In-hospital_death\"].to_numpy().flatten()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:36:12.135292Z",
     "start_time": "2025-03-30T08:35:51.191691Z"
    }
   },
   "source": [
    "# Models\n",
    "# Logistic Regression\n",
    "model1 = LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "model1.fit(X_train,y_train)\n",
    "\n",
    "# Random Forest\n",
    "model2 = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    min_samples_split=5,    \n",
    "    min_samples_leaf=2,         \n",
    "    class_weight='balanced',\n",
    "    random_state=42,        \n",
    ")\n",
    "model2.fit(X_train,y_train)\n",
    "\n",
    "# KNN\n",
    "model3 = KNeighborsClassifier(\n",
    "    n_neighbors=200,\n",
    "    weights='distance',\n",
    "    metric='manhattan',\n",
    ")\n",
    "model3.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=200, weights='distance')"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=200, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=200, weights=&#x27;distance&#x27;)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:36:17.507193Z",
     "start_time": "2025-03-30T08:36:14.305749Z"
    }
   },
   "source": [
    "y_pred1 = model1.predict_proba(X_test)[:,1]\n",
    "y_pred2 = model2.predict_proba(X_test)[:,1]\n",
    "y_pred3 = model3.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculation of AuROC and AuPRC for Logistic Regression\n",
    "print(\"Logistic Regression results\")\n",
    "auroc = roc_auc_score(y_test, y_pred1)\n",
    "print(f\"AUROC: {auroc}\")\n",
    "auprc = average_precision_score(y_test, y_pred1)\n",
    "print(f\"AUPRC: {auprc}\", end=\"\\n\\n\")\n",
    "\n",
    "# Calculation of AuROC and AuPRC for Random Forests\n",
    "print(\"Random Forests results\")\n",
    "auroc = roc_auc_score(y_test, y_pred2)\n",
    "print(f\"AUROC: {auroc}\")\n",
    "auprc = average_precision_score(y_test, y_pred2)\n",
    "print(f\"AUPRC: {auprc}\", end=\"\\n\\n\")\n",
    "\n",
    "# Calculation of AuROC and AuPRC for KNN\n",
    "print(\"KNN results\")\n",
    "auroc = roc_auc_score(y_test, y_pred3)\n",
    "print(f\"AUROC: {auroc}\")\n",
    "auprc = average_precision_score(y_test, y_pred3)\n",
    "print(f\"AUPRC: {auprc}\", end=\"\\n\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression results\n",
      "AUROC: 0.8163296667542642\n",
      "AUPRC: 0.44524358191940566\n",
      "\n",
      "Random Forests results\n",
      "AUROC: 0.8405548672898601\n",
      "AUPRC: 0.46630205253654894\n",
      "\n",
      "KNN results\n",
      "AUROC: 0.817351303324949\n",
      "AUPRC: 0.44402744549028644\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Recurrent Neural Networks (4 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM approach"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:36:20.515774Z",
     "start_time": "2025-03-30T08:36:20.512998Z"
    }
   },
   "source": [
    "# Run in case CUDA_LAUNCH_BLOCKING error occurs\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T08:36:21.432831Z",
     "start_time": "2025-03-30T08:36:21.429003Z"
    }
   },
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:04:21.111152Z",
     "start_time": "2025-03-30T09:04:21.105462Z"
    }
   },
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.7)\n",
    "        self.bn = nn.LayerNorm(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # Extracting output of last timestep\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "\n",
    "        lstm_out = self.bn(lstm_out)\n",
    "\n",
    "        out = self.fc(lstm_out)  \n",
    "        return out\n",
    "    \n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.7, bidirectional=True)\n",
    "\n",
    "        # Adjusted because of bidirectional LSTM\n",
    "        self.bn = nn.LayerNorm(hidden_size * 2)  \n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # Extracting output of last timestep\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "\n",
    "        lstm_out = self.bn(lstm_out)\n",
    "\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:04:23.742736Z",
     "start_time": "2025-03-30T09:04:23.737898Z"
    }
   },
   "source": [
    "# Hyperparameters\n",
    "input_size = 41\n",
    "hidden_size = 256\n",
    "num_layers = 8\n",
    "output_size = 1\n",
    "learning_rate = 0.0003\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "##### NORMAL LSTM\n",
    "# Test AUROC: 0.8218, Test AUPRC: 0.4636 (only set a)\n",
    "\"\"\" input_size = 41\n",
    "hidden_size = 256\n",
    "num_layers = 8\n",
    "output_size = 1\n",
    "learning_rate = 0.0005\n",
    "batch_size = 64\n",
    "num_epochs = 10 \"\"\"\n",
    "\n",
    "# Test AUROC: 0.7828, Test AUPRC: 0.4165 (set a and set b)\n",
    "\"\"\" input_size = 41\n",
    "hidden_size = 256\n",
    "num_layers = 8\n",
    "output_size = 1\n",
    "learning_rate = 0.0005\n",
    "batch_size = 64\n",
    "num_epochs = 9 \"\"\"\n",
    "\n",
    "##### BIDIRECTIONAL LSTM\n",
    "# Test AUROC: 0.8227, Test AUPRC: 0.4557 (Only set a)\n",
    "\"\"\" input_size = 41\n",
    "hidden_size = 256\n",
    "num_layers = 8\n",
    "output_size = 1\n",
    "learning_rate = 0.0003\n",
    "batch_size = 64\n",
    "num_epochs = 3 \"\"\"\n",
    "\n",
    "# Test AUROC: 0.7845, Test AUPRC: 0.4120 (set a and set b)\n",
    "\"\"\" input_size = 41\n",
    "hidden_size = 256\n",
    "num_layers = 8\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 4 \"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' input_size = 41\\nhidden_size = 256\\nnum_layers = 8\\noutput_size = 1\\nlearning_rate = 0.001\\nbatch_size = 64\\nnum_epochs = 4 '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:04:27.588309Z",
     "start_time": "2025-03-30T09:04:26.023961Z"
    }
   },
   "source": [
    "# NOTE: In the scaled-data set the time column is not scaled. However, due to better performance, we still scale it for this application. RecordID can be dropped, since it doesn't convey any further information and each patient is assigned one of the 4000 dimensions.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Training Data\n",
    "df = pd.read_parquet('final-data/final-set-a.parquet')\n",
    "X = df.fillna(0)\n",
    "X = X.groupby(\"RecordID\").tail(49).reset_index(drop=True)\n",
    "X = X.sort_values(by=\"RecordID\", ascending=True)\n",
    "X[\"Time\"] = scaler.fit_transform(X[[\"Time\"]])\n",
    "X = X.drop(columns=[\"RecordID\"])\n",
    "X = X[sorted(X.columns)]\n",
    "X = X.to_numpy()\n",
    "X = X.reshape(4000,49,41)\n",
    "\n",
    "y_df = pd.read_parquet('processed-data/processed-outcomes-a.parquet')\n",
    "y = y_df[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "train_dataset = PatientDataset(X, y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Validation data\n",
    "df = pd.read_parquet('final-data/final-set-b.parquet')\n",
    "X = df.fillna(0)\n",
    "X = X.groupby(\"RecordID\").tail(49).reset_index(drop=True)\n",
    "X = X.sort_values(by=\"RecordID\", ascending=True)\n",
    "X[\"Time\"] = scaler.fit_transform(X[[\"Time\"]])\n",
    "X = X.drop(columns=[\"RecordID\"]).drop(columns=[\"ICUType\"])\n",
    "X = X[sorted(X.columns)]\n",
    "X = X.to_numpy()\n",
    "X = X.reshape(4000,49,41)\n",
    "\n",
    "y_df = pd.read_parquet('processed-data/processed-outcomes-b.parquet')\n",
    "y = y_df[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "val_dataset = PatientDataset(X, y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Test data\n",
    "df = pd.read_parquet('final-data/final-set-c.parquet')\n",
    "X = df.fillna(0)\n",
    "X = X.groupby(\"RecordID\").tail(49).reset_index(drop=True)\n",
    "X = X.sort_values(by=\"RecordID\", ascending=True)\n",
    "X[\"Time\"] = scaler.fit_transform(X[[\"Time\"]])\n",
    "X = X.drop(columns=[\"RecordID\"]).drop(columns=[\"ICUType\"])\n",
    "X = X[sorted(X.columns)]\n",
    "X = X.to_numpy()\n",
    "X = X.reshape(4000,49,41)\n",
    "\n",
    "y_df = pd.read_parquet('processed-data/processed-outcomes-c.parquet')\n",
    "y = y_df[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "test_dataset = PatientDataset(X, y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Full training (use after having found best model with lowest valildation error)\n",
    "df = pd.read_parquet('final-data/final-set-a.parquet')\n",
    "X1 = df.fillna(0)\n",
    "X1 = X1.groupby(\"RecordID\").tail(49).reset_index(drop=True)\n",
    "X1 = X1.sort_values(by=\"RecordID\", ascending=True)\n",
    "X1[\"Time\"] = scaler.fit_transform(X1[[\"Time\"]])\n",
    "X1 = X1[sorted(X1.columns)]\n",
    "df = pd.read_parquet('final-data/final-set-b.parquet')\n",
    "X2 = df.fillna(0)\n",
    "X2 = X2.groupby(\"RecordID\").tail(49).reset_index(drop=True)\n",
    "X2 = X2.sort_values(by=\"RecordID\", ascending=True)\n",
    "X2[\"Time\"] = scaler.fit_transform(X2[[\"Time\"]])\n",
    "X2 = X2.drop(columns=[\"ICUType\"])\n",
    "X2 = X2[sorted(X2.columns)]\n",
    "\n",
    "X_full = pd.concat([X1, X2], axis=0).drop(columns=\"RecordID\")\n",
    "\n",
    "X_full = X_full.to_numpy()\n",
    "X_full = X_full.reshape(8000,49,41)\n",
    "\n",
    "y1 = pd.read_parquet('processed-data/processed-outcomes-b.parquet')\n",
    "y1 = y1[\"In-hospital_death\"].to_numpy().flatten()\n",
    "y2 = pd.read_parquet('processed-data/processed-outcomes-b.parquet')\n",
    "y2 = y2[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "y_full = np.concatenate((y1,y2), axis=0)\n",
    "\n",
    "full_dataset = PatientDataset(X_full, y_full)\n",
    "full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Uncomment/comment line depending on if you want to use normal LSTM or bidirectional LSTM\n",
    "#model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model = BidirectionalLSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop which prints current training loss and validation loss\n",
    "\n",
    "# NOTE: This is for validation error analysis\n",
    "\n",
    "total_val_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval() \n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(test_loader)\n",
    "    total_val_loss += val_loss\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "total_val_loss /= num_epochs\n",
    "print(f\"Avg val loss: {total_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4158, Test AUROC: 0.8012, Test AUPRC: 0.4317\n",
      "Epoch [2/10], Loss: 0.3967, Test AUROC: 0.8170, Test AUPRC: 0.4508\n",
      "Epoch [3/10], Loss: 0.3901, Test AUROC: 0.8058, Test AUPRC: 0.4282\n",
      "Epoch [4/10], Loss: 0.3868, Test AUROC: 0.8054, Test AUPRC: 0.4393\n",
      "Epoch [5/10], Loss: 0.3817, Test AUROC: 0.7882, Test AUPRC: 0.4219\n",
      "Epoch [6/10], Loss: 0.3780, Test AUROC: 0.7869, Test AUPRC: 0.4187\n",
      "Epoch [7/10], Loss: 0.3741, Test AUROC: 0.7851, Test AUPRC: 0.4108\n",
      "Epoch [8/10], Loss: 0.3667, Test AUROC: 0.7724, Test AUPRC: 0.3964\n",
      "Epoch [9/10], Loss: 0.3633, Test AUROC: 0.7709, Test AUPRC: 0.3684\n",
      "Epoch [10/10], Loss: 0.3578, Test AUROC: 0.7615, Test AUPRC: 0.3782\n"
     ]
    }
   ],
   "source": [
    "# Training loop which prints current training loss and AUROC/AUPRC\n",
    "\n",
    "# NOTE: Change train_loader with full_loader if we want to train the model on set a and set b (after validation error analysis)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(full_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(full_loader)\n",
    "\n",
    "    # AUROC & AUPRC calculation\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test AUROC: {auroc:.4f}, Test AUPRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3a Transformers (3 Pts)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:04:32.021182Z",
     "start_time": "2025-03-30T09:04:32.016377Z"
    }
   },
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, d_model=128, num_heads=8, num_layers=3, dim_feedforward=512, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, # Dimensionality of embeddings\n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # FC layer for classification\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.fc(x).squeeze()\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:04:33.731319Z",
     "start_time": "2025-03-30T09:04:33.727351Z"
    }
   },
   "source": [
    "# Model hyperparameters\n",
    "input_size = 41\n",
    "num_classes = 1 \n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "num_layers = 4 \n",
    "dim_feedforward = 512\n",
    "dropout = 0.1\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 10\n",
    "\n",
    "# Test AUROC: 0.8338, Test AUPRC: 0.4719 (Only set a)\n",
    "\"\"\" input_size = 41\n",
    "num_classes = 1 \n",
    "d_model = 128\n",
    "num_heads = 16\n",
    "num_layers = 8\n",
    "dim_feedforward = 512\n",
    "dropout = 0.1\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 6 \"\"\"\n",
    "\n",
    "# Test AUROC: 0.8250, Test AUPRC: 0.4619 (set a and set b)\n",
    "\"\"\" input_size = 41\n",
    "num_classes = 1 \n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "num_layers = 4 \n",
    "dim_feedforward = 512\n",
    "dropout = 0.1\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 3 \"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' input_size = 41\\nnum_classes = 1 \\nd_model = 128\\nnum_heads = 8\\nnum_layers = 4 \\ndim_feedforward = 512\\ndropout = 0.1\\nlearning_rate = 0.0005\\nnum_epochs = 3 '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:04:35.601735Z",
     "start_time": "2025-03-30T09:04:35.583882Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(input_size, num_classes, d_model, num_heads, num_layers, dim_feedforward, dropout).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([7.0]).to(device))  # Handle class imbalance\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T09:10:32.766216Z",
     "start_time": "2025-03-30T09:04:36.733588Z"
    }
   },
   "source": [
    "# Training loop which prints current training loss and AUROC/AUPRC\n",
    "\n",
    "# NOTE: Change train_loader with full_loader if we want to train the model on set a and set b (after validation error analysis)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(full_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(full_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Compute AUROC & AUPRC\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test AUROC: {auroc:.4f}, Test AUPRC: {auprc:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2523, Test AUROC: 0.7984, Test AUPRC: 0.4489\n",
      "Epoch [2/10], Loss: 1.2172, Test AUROC: 0.8065, Test AUPRC: 0.4481\n",
      "Epoch [3/10], Loss: 1.1960, Test AUROC: 0.8282, Test AUPRC: 0.4854\n",
      "Epoch [4/10], Loss: 1.1841, Test AUROC: 0.8329, Test AUPRC: 0.4898\n",
      "Epoch [5/10], Loss: 1.1674, Test AUROC: 0.8238, Test AUPRC: 0.4902\n",
      "Epoch [6/10], Loss: 1.1504, Test AUROC: 0.8055, Test AUPRC: 0.4630\n",
      "Epoch [7/10], Loss: 1.1386, Test AUROC: 0.8094, Test AUPRC: 0.4363\n",
      "Epoch [8/10], Loss: 1.1076, Test AUROC: 0.7965, Test AUPRC: 0.4420\n",
      "Epoch [9/10], Loss: 1.0773, Test AUROC: 0.7908, Test AUPRC: 0.4202\n",
      "Epoch [10/10], Loss: 1.0246, Test AUROC: 0.7489, Test AUPRC: 0.3922\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3b Tokenizing Time-Series Data and Transformers (4 Pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time conversion from \"XX:YY\" to an interval between [0,1]\n",
    "def scale_time(time_str):\n",
    "    # Split the time string into hours and minutes\n",
    "    hours, minutes = map(int, time_str.split(\":\"))\n",
    "    \n",
    "    # Convert the time to total minutes\n",
    "    total_minutes = hours * 60 + minutes\n",
    "    \n",
    "    # Maximum time is 48 hours (2880 minutes)\n",
    "    max_time = 48 * 60\n",
    "    \n",
    "    # Scale time to the range [0, 1]\n",
    "    scaled_time = total_minutes / max_time\n",
    "    return scaled_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding of the different categories\n",
    "categories = [['ALP', 'ALT', 'AST', 'Age', 'Albumin', 'BUN', 'Bilirubin', 'Cholesterol', 'Creatinine', 'DiasABP', 'FiO2',\n",
    "                'GCS', 'Gender', 'Glucose', 'HCO3', 'HCT', 'HR', 'Height', 'K', 'Lactate', 'MAP', 'MechVent', 'Mg', 'NIDiasABP',\n",
    "                'NIMAP', 'NISysABP', 'Na', 'PaCO2', 'PaO2', 'Platelets', 'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI',\n",
    "                'TroponinT', 'Urine', 'WBC', 'Weight', 'pH']]\n",
    "encoder = OneHotEncoder(categories=categories, sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(df):\n",
    "    # Ensure the \"Value\" column is numeric\n",
    "    df = df[pd.to_numeric(df[\"Value\"], errors=\"coerce\").notna()].copy()\n",
    "    df[\"Value\"] = df[\"Value\"].astype(float)\n",
    "\n",
    "    # Apply StandardScaler to the \"Value\" column\n",
    "    scaler = StandardScaler()\n",
    "    df[\"Value\"] = scaler.fit_transform(df[[\"Value\"]])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Getting max_sequence_length (= 1500, needed for padding the sequences). Note that set-a contains the largest sequence\n",
    "file_paths = glob.glob(\"data/set-a/*.txt\")\n",
    "max_sequence_length = 0\n",
    "\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[df['Parameter'] != 'ICUType']\n",
    "    df = df[df['Parameter'] != 'RecordID']\n",
    "    if(len(df) > max_sequence_length):\n",
    "        max_sequence_length = len(df)\n",
    "\n",
    "# Experimental: Clip max_sequence_length to 1000\n",
    "max_sequence_length = 1000\n",
    "print(max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing of Set-a done\n",
      "Processing of Set-b done\n",
      "Processing of Set-c done\n"
     ]
    }
   ],
   "source": [
    "# Processing all sequences and appending them to a list for extracting the embeddings\n",
    "\n",
    "time_sequences_a = []\n",
    "category_sequences_a = []\n",
    "value_sequences_a = []\n",
    "\n",
    "time_sequences_b = []\n",
    "category_sequences_b = []\n",
    "value_sequences_b = []\n",
    "\n",
    "time_sequences_c = []\n",
    "category_sequences_c = []\n",
    "value_sequences_c = []\n",
    "\n",
    "\n",
    "# Set-a processing\n",
    "file_paths = glob.glob(\"data/set-a/*.txt\")\n",
    "i = 0\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Filter out \"ICUType\" & \"RecordID\"\n",
    "    df = df[df['Parameter'] != 'ICUType']\n",
    "    df = df[df['Parameter'] != 'RecordID']\n",
    "\n",
    "    # Time scaling\n",
    "    df[\"Time\"] = df[\"Time\"].apply(scale_time).astype(float)\n",
    "\n",
    "    # Parameter one-hot encoding\n",
    "    parameter_column = df[\"Parameter\"].values.reshape(-1, 1)\n",
    "    encoded_params = encoder.fit_transform(parameter_column)\n",
    "    indices = np.argmax(encoded_params, axis=1)\n",
    "    df[\"Parameter\"] = indices\n",
    "\n",
    "    # Scaling the values\n",
    "    df = scale_values(df)\n",
    "    \n",
    "    time_sequences_a.append(torch.tensor(df[\"Time\"].to_numpy()))\n",
    "    category_sequences_a.append(torch.tensor(df[\"Parameter\"].to_numpy()))\n",
    "    value_sequences_a.append(torch.tensor(df[\"Value\"].to_numpy()))\n",
    "\n",
    "print(\"Processing of Set-a done\")    \n",
    "\n",
    "\n",
    "# Set-b processing\n",
    "file_paths = glob.glob(\"data/set-b/*.txt\")\n",
    "i = 0\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Filter out \"ICUType\" & \"RecordID\"\n",
    "    df = df[df['Parameter'] != 'ICUType']\n",
    "    df = df[df['Parameter'] != 'RecordID']\n",
    "\n",
    "    # Time scaling\n",
    "    df[\"Time\"] = df[\"Time\"].apply(scale_time).astype(float)\n",
    "\n",
    "    # Parameter one-hot encoding\n",
    "    parameter_column = df[\"Parameter\"].values.reshape(-1, 1)\n",
    "    encoded_params = encoder.fit_transform(parameter_column)\n",
    "    indices = np.argmax(encoded_params, axis=1)\n",
    "    df[\"Parameter\"] = indices\n",
    "\n",
    "    # Scaling the values\n",
    "    df = scale_values(df)\n",
    "    \n",
    "    time_sequences_b.append(torch.tensor(df[\"Time\"].to_numpy()))\n",
    "    category_sequences_b.append(torch.tensor(df[\"Parameter\"].to_numpy()))\n",
    "    value_sequences_b.append(torch.tensor(df[\"Value\"].to_numpy()))\n",
    "\n",
    "print(\"Processing of Set-b done\")\n",
    "\n",
    "\n",
    "# Set-c processing\n",
    "file_paths = glob.glob(\"data/set-c/*.txt\")\n",
    "i = 0\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Filter out \"ICUType\" & \"RecordID\"\n",
    "    df = df[df['Parameter'] != 'ICUType']\n",
    "    df = df[df['Parameter'] != 'RecordID']\n",
    "    df = df[df['Parameter'] != '']\n",
    "\n",
    "    # Remove nans in parameter column\n",
    "    df = df.dropna(subset=[\"Parameter\"])\n",
    "\n",
    "    # Time scaling\n",
    "    df[\"Time\"] = df[\"Time\"].apply(scale_time).astype(float)\n",
    "\n",
    "    # Parameter one-hot encoding\n",
    "    parameter_column = df[\"Parameter\"].values.reshape(-1, 1)\n",
    "    encoded_params = encoder.fit_transform(parameter_column)\n",
    "    indices = np.argmax(encoded_params, axis=1)\n",
    "    df[\"Parameter\"] = indices\n",
    "\n",
    "    # Scaling the values\n",
    "    df = scale_values(df)\n",
    "    \n",
    "    time_sequences_c.append(torch.tensor(df[\"Time\"].to_numpy()))\n",
    "    category_sequences_c.append(torch.tensor(df[\"Parameter\"].to_numpy()))\n",
    "    value_sequences_c.append(torch.tensor(df[\"Value\"].to_numpy()))\n",
    "\n",
    "print(\"Processing of Set-c done\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_variables = 40\n",
    "embedding_dim = 20\n",
    "\n",
    "# Embedding layer for categorical/parameter variables\n",
    "variable_embedding = nn.Embedding(num_variables, embedding_dim)\n",
    "\n",
    "# Linear layer to project (time, value) into the same space\n",
    "time_value_proj = nn.Linear(2, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patient_data(time_sequences, category_sequences, value_sequences):\n",
    "    # Convert categorical variables to embeddings\n",
    "    var_embeddings = [variable_embedding(seq) for seq in category_sequences]\n",
    "\n",
    "    # Stack and project time and value\n",
    "    time_value_seqs = [torch.cat([t.unsqueeze(1), v.unsqueeze(1)], dim=1).to(torch.float32) for t, v in zip(time_sequences, value_sequences)]\n",
    "    time_value_embeddings = [time_value_proj(seq) for seq in time_value_seqs]\n",
    "\n",
    "    # Concatenate everything\n",
    "    final_sequences = [torch.cat([var_emb, tv_emb], dim=1) \n",
    "                       for var_emb, tv_emb in zip(var_embeddings, time_value_embeddings)]\n",
    "\n",
    "    # Pad sequences to a fixed length of max_sequence_length\n",
    "    max_len = max_sequence_length\n",
    "    padded_sequences = torch.zeros(len(final_sequences), max_len, final_sequences[0].size(1))\n",
    "\n",
    "    for i, seq in enumerate(final_sequences):\n",
    "        length = min(seq.size(0), max_len)\n",
    "        padded_sequences[i, :length, :] = seq[:length]\n",
    "    \n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 1000, 40])\n",
      "torch.Size([4000, 1000, 40])\n",
      "torch.Size([4000, 1000, 40])\n"
     ]
    }
   ],
   "source": [
    "# Getting embeddings which are the inputs of the transformer\n",
    "padded_sequences_a = process_patient_data(time_sequences_a, category_sequences_a, value_sequences_a)\n",
    "padded_sequences_b = process_patient_data(time_sequences_b, category_sequences_b, value_sequences_b)\n",
    "padded_sequences_c = process_patient_data(time_sequences_c, category_sequences_c, value_sequences_c)\n",
    "print(padded_sequences_a.shape)\n",
    "print(padded_sequences_b.shape)\n",
    "print(padded_sequences_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientSequences(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings.clone().detach().float()\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "def get_dataloader(embeddings, labels, batch_size=32, shuffle=True):\n",
    "    dataset = PatientSequences(embeddings, labels)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_sequences_a\n",
    "y = pd.read_parquet('processed-data/processed-outcomes-a.parquet')\n",
    "y = y[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "train_dataset = PatientSequences(X, y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "X = padded_sequences_b\n",
    "y = pd.read_parquet('processed-data/processed-outcomes-b.parquet')\n",
    "y = y[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "val_dataset = PatientSequences(X, y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "X = padded_sequences_c\n",
    "y = pd.read_parquet('processed-data/processed-outcomes-c.parquet')\n",
    "y = y[\"In-hospital_death\"].to_numpy().flatten()\n",
    "\n",
    "test_dataset = PatientSequences(X, y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=max_sequence_length):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.shape[1], :]\n",
    "\n",
    "class PreNormTransformerLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x), attn_mask=mask, need_weights=False)[0]\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim=50, nhead=4, num_layers=3, dim_feedforward=128, dropout=0.2, max_sequence_length=max_sequence_length):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.positional_encoding = SinusoidalPositionalEncoding(input_dim, max_sequence_length)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            PreNormTransformerLayer(input_dim, nhead, dim_feedforward, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.positional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' input_dim = 40\\nhidden_dim = 256         \\nnum_heads = 4          \\nnum_layers = 4        \\nlearning_rate = 0.0005\\nnum_epochs = 11 '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 40\n",
    "hidden_dim = 256         \n",
    "num_heads = 4          \n",
    "num_layers = 4        \n",
    "learning_rate = 0.0005\n",
    "num_epochs = 10\n",
    "\n",
    "# Test AUROC: 0.7714, Test AUPRC: 0.3392\n",
    "\"\"\" input_dim = 40\n",
    "hidden_dim = 256         \n",
    "num_heads = 4          \n",
    "num_layers = 4        \n",
    "learning_rate = 0.0005\n",
    "num_epochs = 11 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(input_dim, num_heads, num_layers).to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop which prints current training loss and validation loss\n",
    "\n",
    "# NOTE: This is for validation error analysis\n",
    "\n",
    "total_val_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval() \n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(test_loader)\n",
    "    total_val_loss += val_loss\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "total_val_loss /= num_epochs\n",
    "print(f\"Avg val loss: {total_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4348, Test AUROC: 0.6171, Test AUPRC: 0.2191\n",
      "Epoch [2/10], Loss: 0.3997, Test AUROC: 0.6474, Test AUPRC: 0.2316\n",
      "Epoch [3/10], Loss: 0.3924, Test AUROC: 0.6948, Test AUPRC: 0.2775\n",
      "Epoch [4/10], Loss: 0.3872, Test AUROC: 0.7152, Test AUPRC: 0.2753\n",
      "Epoch [5/10], Loss: 0.3760, Test AUROC: 0.7343, Test AUPRC: 0.2852\n",
      "Epoch [6/10], Loss: 0.3680, Test AUROC: 0.7616, Test AUPRC: 0.3350\n",
      "Epoch [7/10], Loss: 0.3517, Test AUROC: 0.7664, Test AUPRC: 0.3509\n",
      "Epoch [8/10], Loss: 0.3495, Test AUROC: 0.7637, Test AUPRC: 0.3498\n",
      "Epoch [9/10], Loss: 0.3486, Test AUROC: 0.7684, Test AUPRC: 0.3532\n",
      "Epoch [10/10], Loss: 0.3398, Test AUROC: 0.7699, Test AUPRC: 0.3624\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Compute AUROC & AUPRC\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test AUROC: {auroc:.4f}, Test AUPRC: {auprc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
